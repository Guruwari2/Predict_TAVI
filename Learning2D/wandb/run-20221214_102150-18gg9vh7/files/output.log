
Epoch: 1
tensor([[0.9943, 0.7115, 0.8582, 0.8346, 1.0636, 0.7451, 1.1027, 0.9472, 0.9331,
         0.8479, 0.9964, 0.8712, 1.0642, 0.9154, 0.7201, 0.6070, 1.1774, 0.9370,
         0.7468, 0.6088, 0.7182, 1.0729, 0.6480, 0.9370, 0.5808, 0.4890, 0.6887,
         0.8297, 0.8165, 0.8739, 0.6621, 0.4801, 0.8892, 0.9121, 1.1243, 1.0175,
         1.1957, 0.7792, 1.1909, 0.7353, 0.7319, 0.9434, 0.6006, 0.4169, 0.7589,
         0.4849, 0.4956, 0.4492, 0.5088, 0.2292, 0.4219, 0.3476, 0.4545, 0.4781,
         0.6067, 0.6808, 1.0617, 0.5602, 0.6121, 0.7005, 0.5952, 0.6591, 0.6724,
         0.4929, 0.4666, 0.5499, 0.4566, 0.7764, 0.6492, 0.8370, 0.7258, 0.7169,
         0.7837, 0.6598, 0.6485, 0.5498, 0.5600, 0.7318, 0.4644, 0.5989, 0.4345,
         0.4597, 0.6769, 0.3154, 0.3158, 0.4741, 0.6886, 0.4380, 0.6893, 0.7104,
         0.5561, 0.6192, 0.5465, 0.2800, 0.3728, 0.6442, 0.6938, 0.8006],
        [0.6167, 0.6704, 0.8666, 1.0047, 0.7253, 0.8407, 0.5448, 0.6665, 0.6946,
         0.6305, 0.8739, 1.0376, 0.9486, 0.8734, 0.8824, 1.1889, 0.8299, 0.7042,
         0.4866, 0.4255, 0.3948, 0.6502, 0.6296, 0.7840, 0.6785, 0.3662, 0.5437,
         0.6535, 0.6447, 0.6398, 0.7403, 0.5408, 0.4840, 0.3933, 0.5884, 0.6154,
         0.9336, 0.6018, 0.5078, 0.3291, 0.4577, 0.4265, 0.4525, 0.3258, 0.5689,
         0.5841, 0.4133, 0.7531, 0.6340, 0.7635, 0.9567, 0.6838, 0.3839, 0.3954,
         0.4899, 0.6815, 0.4695, 0.5191, 0.7435, 0.5629, 0.6618, 0.3930, 0.8123,
         0.9218, 0.5258, 0.7361, 0.7842, 0.7049, 0.8084, 0.6892, 0.6276, 0.5257,
         0.4662, 0.5302, 0.6338, 0.7037, 0.7545, 1.0385, 1.3812, 1.5225, 1.2909,
         0.9502, 1.2039, 0.9878, 0.6984, 0.4318, 0.4686, 0.4051, 0.2752, 0.1766,
         0.3551, 0.3391, 0.2500, 0.3027, 0.5548, 0.4786, 0.4243, 0.4441],
        [0.6542, 0.6410, 0.7176, 0.6543, 0.5708, 0.7076, 0.5705, 0.3597, 0.5076,
         0.4080, 0.3385, 0.6999, 0.7472, 0.6123, 0.7900, 0.6689, 0.8807, 0.6655,
         0.3203, 0.6907, 0.4941, 0.5108, 0.5004, 0.6369, 0.6055, 0.3349, 0.4018,
         0.6614, 0.5410, 0.5252, 0.4381, 0.7601, 0.7502, 0.3629, 0.3683, 0.5579,
         0.3009, 0.7748, 0.5002, 0.4991, 0.7174, 0.4756, 0.2417, 0.6725, 0.4508,
         0.6861, 0.7720, 0.7076, 1.2631, 0.8562, 0.7748, 0.6968, 0.9013, 0.9747,
         0.5469, 0.4469, 0.9559, 0.6794, 0.4794, 0.7427, 0.6611, 0.6887, 0.7962,
         0.3648, 0.7192, 0.5491, 0.6389, 0.5163, 0.6196, 0.8569, 0.6184, 0.9986,
         0.8593, 0.6379, 0.5414, 0.3895, 0.7693, 0.6739, 1.0253, 1.0131, 0.7538,
         0.6775, 0.9579, 0.6700, 0.7216, 0.6360, 0.8620, 0.6271, 0.7276, 0.8606,
         0.6091, 0.4273, 0.3678, 0.4093, 0.4001, 0.6269, 0.6717, 0.5591],
        [0.5291, 0.7152, 0.6320, 0.5672, 0.8200, 0.6612, 0.4054, 0.3844, 0.3447,
         0.3434, 0.3594, 0.2828, 0.3385, 0.4893, 0.2936, 0.4151, 0.4214, 0.5706,
         0.6678, 0.4228, 0.4715, 0.3645, 0.4516, 0.5170, 0.4992, 0.6587, 0.3811,
         0.4803, 0.5746, 0.6819, 0.4275, 0.3997, 0.6512, 0.6375, 0.4290, 0.3401,
         0.3078, 0.4534, 0.7862, 0.7278, 0.5307, 0.8442, 0.8241, 0.7848, 0.4177,
         0.5134, 0.3859, 0.3004, 0.5295, 0.4333, 0.4608, 0.5142, 0.6714, 0.4719,
         0.5948, 0.5749, 0.6672, 0.5934, 0.5206, 0.8763, 1.5663, 0.8762, 0.7918,
         0.8357, 0.5610, 0.6545, 0.5722, 0.6327, 0.4306, 0.5949, 0.4842, 0.3768,
         0.4420, 0.2294, 0.2641, 0.3986, 0.4827, 0.5716, 0.9023, 0.5194, 0.4682,
         0.8303, 0.7651, 0.6411, 0.5029, 0.5347, 0.5051, 0.7228, 0.5045, 0.4842,
         0.4943, 0.3285, 0.5579, 0.4451, 0.4255, 0.6833, 0.3886, 0.5666],
        [1.0829, 1.0923, 1.0949, 0.7573, 1.0319, 0.7523, 0.8826, 0.5516, 0.5948,
         0.8565, 0.6273, 0.7739, 0.5218, 1.2645, 1.4194, 0.7460, 1.0923, 0.9247,
         1.0209, 0.5826, 0.9586, 1.3717, 0.7946, 0.5009, 0.9805, 0.9823, 0.9012,
         0.8194, 0.6010, 0.8489, 1.0265, 1.0716, 1.1916, 0.7756, 1.0923, 1.0978,
         0.6698, 0.6946, 1.0144, 0.7886, 1.2262, 1.2941, 1.1458, 1.3863, 1.5202,
         1.2969, 0.9232, 1.2923, 0.7862, 0.9057, 1.3702, 1.0060, 1.1828, 1.1518,
         0.7474, 1.0607, 0.7022, 0.8621, 0.9428, 1.1886, 0.9676, 0.9502, 0.8669,
         0.8499, 0.9195, 0.9204, 0.8392, 0.9918, 1.1372, 0.9550, 0.9347, 0.9716,
         1.0335, 0.8869, 0.9060, 0.6346, 0.4891, 0.7031, 0.6427, 0.6484, 0.8679,
         0.8005, 0.7649, 0.5735, 0.5208, 0.7746, 0.8303, 0.8119, 0.5167, 0.4455,
         0.3724, 0.1859, 0.6849, 0.4629, 0.5771, 0.6272, 0.6641, 0.5632],
        [0.4959, 0.3910, 0.3754, 0.3545, 0.6574, 0.4966, 0.6022, 0.6797, 0.8565,
         0.5328, 0.4750, 0.5773, 0.5472, 1.1072, 1.0228, 0.7682, 0.5621, 0.8843,
         0.9127, 0.6743, 0.8791, 1.0069, 0.8807, 0.7465, 0.9429, 1.2221, 1.2725,
         0.7487, 0.5846, 0.6893, 0.7854, 0.8424, 0.7418, 0.5246, 0.8092, 0.6197,
         0.6096, 1.0035, 1.1148, 0.9039, 1.3086, 1.2080, 1.0716, 1.1161, 0.8470,
         0.8790, 0.7246, 0.8887, 0.8459, 0.8882, 0.7122, 0.9464, 0.6415, 0.6145,
         0.5944, 1.0366, 0.6857, 0.7745, 1.2760, 0.7563, 0.8092, 0.9474, 0.7504,
         1.0134, 0.9130, 1.0732, 1.2873, 0.8436, 1.1841, 0.8360, 0.6187, 1.4997,
         1.0144, 1.1700, 0.8147, 0.9465, 0.8460, 0.7587, 0.7199, 0.5742, 0.6493,
         0.5549, 0.3597, 0.6758, 0.8911, 0.5903, 0.3634, 0.6630, 0.4815, 0.3474,
         0.4267, 0.3347, 0.2807, 0.2227, 0.2018, 0.3050, 0.2757, 0.6524]],
       device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)
Traceback (most recent call last):
  File "main.py", line 87, in <module>
    train_loss = train_func(model, loader_train, optimizer, scaler)
  File "/homes/n20darja/StageCesureCoeur/predict_tavi/Learning2D/train.py", line 41, in train_func
    total_loss += loss.item()
ValueError: only one element tensors can be converted to Python scalars
Traceback (most recent call last):
  File "main.py", line 87, in <module>
    train_loss = train_func(model, loader_train, optimizer, scaler)
  File "/homes/n20darja/StageCesureCoeur/predict_tavi/Learning2D/train.py", line 41, in train_func
    total_loss += loss.item()
ValueError: only one element tensors can be converted to Python scalars